{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a73946",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e77751",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class LensDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.files = list(self.root_dir.rglob('*.npy'))\n",
    "        self.labels = [self.get_label(f) for f in self.files]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def get_label(self, file):\n",
    "        if 'vort' in str(file):\n",
    "            return 0\n",
    "        elif 'sphere' in str(file):\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.load(self.files[idx], allow_pickle=True)\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img.to(device), torch.tensor(self.labels[idx]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1207ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop((150, 150), scale=(0.7, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "project_root = Path('/Users/pushpakumar/Projects/GSoC25_DeepLense-Gravitational Lens Finding /Common_Test-I-MultiClass')\n",
    "train_data = LensDataset(project_root / 'dataset'/'train', transform=transform)\n",
    "val_data = LensDataset(project_root / 'dataset'/'val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ResNet18 with modified first layer for single-channel input\n",
    "model = models.resnet18(weights=None)  # Do not download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first convolutional layer for 1-channel input\n",
    "model.conv1 = nn.Conv2d(1, 128, kernel_size=7, stride=2, padding=3, bias=False)  # Increased filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69097ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the corresponding batch normalization layer\n",
    "model.bn1 = nn.BatchNorm2d(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first residual block (layer1) to accept 128 input channels\n",
    "model.layer1[0].conv1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.layer1[0].bn1 = nn.BatchNorm2d(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the downsample layer in the first residual block to handle 128 input channels\n",
    "model.layer1[0].downsample = nn.Sequential(\n",
    "    nn.Conv2d(128, 64, kernel_size=1, stride=1, bias=False),\n",
    "    nn.BatchNorm2d(64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5716335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the final fully connected layer for 3-class output\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights (excluding incompatible layers)\n",
    "weights_path = \"/Users/pushpakumar/Downloads/resnet18-f37072fd.pth\"\n",
    "pretrained_dict = torch.load(weights_path)\n",
    "model_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out incompatible keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model's state dict\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12988554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with adjusted class weights\n",
    "class_weights = torch.tensor([1.0, 2.0, 1.0]).to(device)  # Adjusted for class imbalance\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ed47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Increased learning rate\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b02963",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Early stopping with increased patience\n",
    "early_stopping_patience = 5  # Increased from 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e832fa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "def train_model(model, train_loader, val_loader, epochs=20):\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    # Declare global variables\n",
    "    global best_val_loss, patience_counter\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        # Save checkpoint after each epoch\n",
    "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5a730",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plot training and validation losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1cc4a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Evaluate model (ROC curve and AUC)\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    y_true, y_scores = [], [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            y_scores.extend(probs)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "\n",
    "    for i in range(3):\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_scores[:, i])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc_score:.2f})')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f3e11",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448314a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "def print_confusion_matrix(model, val_loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5094bf0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print_confusion_matrix(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9db2a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Sample image visualization\n",
    "def show_sample_images(dataset, num_samples=5):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        img, label = dataset[i]\n",
    "        img = img.squeeze().cpu().numpy()\n",
    "        img = (img + 1) / 2  # Change range from [-1, 1] to [0, 1]\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6440c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_images(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642a559",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
